{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recommender import Recommender\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from eval_model import TopQuantileEvaluator, NDCGEvaluator, NDCG10Evaluator\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "quant_evaluator = TopQuantileEvaluator()\n",
    "\n",
    "ndcg_evaluator = NDCGEvaluator()\n",
    "\n",
    "ndcg10_evaluator = NDCG10Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: byte (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load restaurant reviews\n",
    "reviews_df = spark.read.parquet('../data/ratings_ugt10_igt10')\n",
    "\n",
    "# Randomly split data into train and test datasets\n",
    "train_df, test_df = reviews_df.randomSplit(weights=[0.75, 0.25])\n",
    "\n",
    "print(train_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: byte (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "estimator = Recommender(\n",
    "    useALS=True,\n",
    "    useBias=True,\n",
    "    lambda_1=7,\n",
    "    lambda_2=12,\n",
    "    userCol='user',\n",
    "    itemCol='item',\n",
    "    ratingCol='rating',\n",
    "    rank=76,\n",
    "    regParam=0.7,\n",
    "    maxIter=15,\n",
    "    nonnegative=True\n",
    ")\n",
    "model = estimator.fit(train_df)\n",
    "\n",
    "train_predictions_df = model.transform(train_df)\n",
    "predictions_df = model.transform(test_df)\n",
    "\n",
    "print(predictions_df.printSchema())\n",
    "\n",
    "train_predictions_df.registerTempTable(\"train_predictions_df\")\n",
    "predictions_df.registerTempTable(\"predictions_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ndcg:  0.042821942740194796\n",
      "test ndcg:  0.03582585416572548\n",
      "train ndcg10:  0.08353896455358423\n",
      "test ndcg10:  0.043665789170521885\n"
     ]
    }
   ],
   "source": [
    "# print('rmse: ', rmse_evaluator.evaluate(predictions_df))\n",
    "# print('quant: ', quant_evaluator.evaluate(predictions_df))\n",
    "print('train ndcg: ', ndcg_evaluator.evaluate(train_predictions_df))\n",
    "print('test ndcg: ', ndcg_evaluator.evaluate(predictions_df))\n",
    "print('train ndcg10: ', ndcg10_evaluator.evaluate(train_predictions_df))\n",
    "print('test ndcg10: ', ndcg10_evaluator.evaluate(predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user=148, item=1238, rating=4, prediction=3.3150130676480636),\n",
       " Row(user=148, item=623, rating=3, prediction=3.4296339710792374),\n",
       " Row(user=148, item=588, rating=5, prediction=3.2206168163144557),\n",
       " Row(user=148, item=3062, rating=4, prediction=2.774133942817688),\n",
       " Row(user=148, item=321, rating=4, prediction=3.20498255146401),\n",
       " Row(user=148, item=642, rating=4, prediction=3.0863614245593887),\n",
       " Row(user=148, item=939, rating=3, prediction=2.311904546767229),\n",
       " Row(user=148, item=210, rating=4, prediction=3.3664048779724496),\n",
       " Row(user=148, item=236, rating=5, prediction=3.7750855149844114),\n",
       " Row(user=148, item=1085, rating=4, prediction=2.887221045362643),\n",
       " Row(user=148, item=140, rating=5, prediction=3.652437360852982),\n",
       " Row(user=148, item=1311, rating=4, prediction=3.165601377220902),\n",
       " Row(user=148, item=715, rating=4, prediction=3.2322611294828576),\n",
       " Row(user=148, item=992, rating=5, prediction=3.5874774410188017),\n",
       " Row(user=148, item=699, rating=5, prediction=3.396021077389607),\n",
       " Row(user=148, item=1917, rating=4, prediction=3.2989496856353426),\n",
       " Row(user=148, item=1360, rating=4, prediction=3.5142382787570945),\n",
       " Row(user=148, item=3947, rating=3, prediction=2.340482455940527),\n",
       " Row(user=148, item=2257, rating=4, prediction=3.610805486981832),\n",
       " Row(user=148, item=1180, rating=5, prediction=2.958986182189113),\n",
       " Row(user=148, item=1649, rating=4, prediction=2.6257657918062165),\n",
       " Row(user=148, item=4211, rating=3, prediction=2.0988281707064633),\n",
       " Row(user=148, item=462, rating=4, prediction=3.6698348171337187),\n",
       " Row(user=148, item=981, rating=4, prediction=2.384387503985767),\n",
       " Row(user=148, item=2784, rating=4, prediction=3.156028711421607),\n",
       " Row(user=148, item=49, rating=5, prediction=3.5721806609302327),\n",
       " Row(user=148, item=4058, rating=3, prediction=2.4046870111925998),\n",
       " Row(user=148, item=171, rating=4, prediction=2.994753290885841),\n",
       " Row(user=148, item=389, rating=3, prediction=3.307041999279223),\n",
       " Row(user=148, item=395, rating=5, prediction=3.3650775798530628),\n",
       " Row(user=148, item=2226, rating=5, prediction=3.4316661846513856),\n",
       " Row(user=148, item=1147, rating=4, prediction=2.908216732723578),\n",
       " Row(user=148, item=1345, rating=4, prediction=3.2052928481271756),\n",
       " Row(user=148, item=4392, rating=4, prediction=2.0141891871570383),\n",
       " Row(user=148, item=369, rating=4, prediction=2.888192494549502),\n",
       " Row(user=148, item=2894, rating=4, prediction=2.9139560922232812),\n",
       " Row(user=148, item=2946, rating=4, prediction=3.412380601178704),\n",
       " Row(user=148, item=379, rating=4, prediction=3.2668717940677983),\n",
       " Row(user=148, item=1571, rating=4, prediction=3.194191799376089),\n",
       " Row(user=148, item=3989, rating=5, prediction=3.397778247536092)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user=0, count=236),\n",
       " Row(user=1, count=179),\n",
       " Row(user=2, count=168),\n",
       " Row(user=3, count=142),\n",
       " Row(user=4, count=139),\n",
       " Row(user=12, count=114),\n",
       " Row(user=6, count=113),\n",
       " Row(user=7, count=113),\n",
       " Row(user=8, count=104),\n",
       " Row(user=10, count=98)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.groupBy('user').count().orderBy('count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|user|              ndcg|\n",
      "+----+------------------+\n",
      "| 148|0.9728784174019554|\n",
      "| 463|0.9722430018359393|\n",
      "| 471|0.9643870276112828|\n",
      "| 496|0.9487168757638186|\n",
      "| 833|0.9757471111120347|\n",
      "|1088|0.9818244946677487|\n",
      "|1238|0.9837089947755142|\n",
      "|1342|0.8730689413392722|\n",
      "|1580|0.9182753535720931|\n",
      "|1591|0.9623163943935841|\n",
      "+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "+----+------------------+\n",
      "|user|            ndcg10|\n",
      "+----+------------------+\n",
      "| 148|0.8552441410049546|\n",
      "| 463|0.8998231837904668|\n",
      "| 471|0.8904629554697352|\n",
      "| 496|0.9022594525255184|\n",
      "| 833|0.9424659505448238|\n",
      "|1088|0.9586566196543211|\n",
      "|1238|0.9281860059485352|\n",
      "|1342| 0.740790364549004|\n",
      "|1580|0.9182753535720931|\n",
      "|1591|0.9158825646429439|\n",
      "+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df2a = spark.sql(\n",
    "'''\n",
    "    select\n",
    "        user,\n",
    "        sum(dcg) / sum(idcg) as ndcg\n",
    "    from (\n",
    "        select\n",
    "            user,\n",
    "            rating / log(2, 1 + \n",
    "                row_number() OVER (\n",
    "                    PARTITION BY user\n",
    "                    ORDER BY prediction DESC\n",
    "                )\n",
    "            ) as dcg,\n",
    "            rating / log(2, 1 + \n",
    "                row_number() OVER (\n",
    "                        PARTITION BY user\n",
    "                        ORDER BY rating DESC\n",
    "                    )\n",
    "            ) as idcg\n",
    "        from predictions_df\n",
    "    ) x\n",
    "    group by user\n",
    "\n",
    "'''\n",
    ")\n",
    "\n",
    "\n",
    "df2b = spark.sql(\n",
    "'''\n",
    "    select \n",
    "        p.user,\n",
    "        p.dcg / a.idcg as ndcg10\n",
    "    from (\n",
    "        select\n",
    "            x.user,\n",
    "            sum(x.rating / log(2, 1 + x.pred_row_num)) as dcg\n",
    "        from (\n",
    "            select\n",
    "                user,\n",
    "                rating,\n",
    "                row_number() OVER (\n",
    "                    PARTITION BY user\n",
    "                    ORDER BY prediction DESC\n",
    "                ) as pred_row_num\n",
    "            from predictions_df\n",
    "        ) x \n",
    "        where x.pred_row_num <= 10\n",
    "        group by x.user\n",
    "    ) p\n",
    "    join (\n",
    "        select\n",
    "            x.user,\n",
    "            sum(x.rating / log(2, 1 + x.actual_row_num)) as idcg\n",
    "        from (\n",
    "            select\n",
    "                user,\n",
    "                rating,\n",
    "                row_number() OVER (\n",
    "                    PARTITION BY user\n",
    "                    ORDER BY rating DESC\n",
    "                ) as actual_row_num\n",
    "            from predictions_df\n",
    "        ) x \n",
    "        where x.actual_row_num <= 10\n",
    "        group by x.user\n",
    "    ) a on a.user = p.user\n",
    "'''\n",
    ")\n",
    "\n",
    "print(df2a.show(10))\n",
    "print(df2b.show(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "|user|item|rating|        prediction|                dcg|               idcg|pred_row_num|ideal_row_num|\n",
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "|1088| 658|     5|3.5237720644899895|                5.0|                5.0|           1|            1|\n",
      "|1088| 399|     4|3.3947158620042472| 2.5237190142858297|                2.0|           2|            3|\n",
      "|1088| 873|     5|3.3131666746353954|                2.5|  3.154648767857287|           3|            2|\n",
      "|1088| 150|     4|3.2764287410539943| 1.7227062322935722| 1.7227062322935722|           4|            4|\n",
      "|1088|   1|     3| 3.244822264374948| 1.1605584217036249| 0.7879486051115807|           5|           13|\n",
      "|1088|  58|     4|3.1331424303603477| 1.4248287484320887| 1.5474112289381665|           6|            5|\n",
      "|1088|  33|     4|3.0242493870936222| 1.3333333333333333| 1.4248287484320887|           7|            6|\n",
      "|1088| 518|     4|3.0150088768290235| 1.2618595071429148| 1.3333333333333333|           8|            7|\n",
      "|1088| 250|     3|  2.88649888994604| 0.9030899869919435| 0.7678740744294464|           9|           14|\n",
      "|1088| 119|     4|2.8218682602834155| 1.1562593052715513| 1.2618595071429148|          10|            8|\n",
      "|1088| 164|     4|2.8152557184315077| 1.1157717826045193| 1.2041199826559246|          11|            9|\n",
      "|1088|1989|     1|2.7162316292182487|0.27023815442731974|0.22106472945750374|          12|           22|\n",
      "|1088| 412|     3|2.6982743994108818| 0.7879486051115807|               0.75|          13|           15|\n",
      "|1088| 476|     2|2.6374080119701055|  0.511916049619631| 0.4708178267332765|          14|           18|\n",
      "|1088|1382|     4| 2.601330728894953|                1.0| 1.1562593052715513|          15|           10|\n",
      "|1088| 294|     4|2.6006365426805766| 0.9786021684729039| 1.1157717826045193|          16|           11|\n",
      "|1088| 686|     3| 2.537653782825404| 0.7194373997043944|  0.733951626354678|          17|           16|\n",
      "|1088|1685|     2|2.4856925425813667| 0.4708178267332765| 0.4627564263195183|          18|           19|\n",
      "|1088| 808|     1|2.4413620147937998|0.23137821315975915|0.21810429198553152|          19|           23|\n",
      "|1088| 388|     4|2.4079395951481217|  0.910680994787812|  1.080952617709279|          20|           12|\n",
      "|1088| 953|     2| 2.382041992688878| 0.4484876484351509|  0.455340497393906|          21|           20|\n",
      "|1088| 540|     2|2.1094626621055976| 0.4421294589150075| 0.4484876484351509|          22|           21|\n",
      "|1088| 135|     3|1.9362903813782637| 0.6543128759565946| 0.7194373997043944|          23|           17|\n",
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.sql(\n",
    "'''\n",
    "select\n",
    "    user,\n",
    "    item,\n",
    "    rating,\n",
    "    prediction,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "            PARTITION BY user\n",
    "            ORDER BY prediction DESC\n",
    "        )\n",
    "    ) as dcg,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY rating DESC\n",
    "            )\n",
    "    ) as idcg,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY prediction DESC\n",
    "    ) as pred_row_num,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY rating DESC\n",
    "    ) as ideal_row_num\n",
    "from predictions_df\n",
    "where user = 1088\n",
    "order by pred_row_num\n",
    "'''\n",
    ")\n",
    "df3.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_df = spark.createDataFrame([\n",
    "    (1,1,1,3.8), (1,2,3,3.8), (1,3,1,3.8), (1,4,1,3.8), (1,5,5,3.8),\n",
    "    (1,6,4,3.8), (1,7,5,3.8), (1,8,5,3.8), (1,9,5,3.8), (1,10,5,3.8),\n",
    "],['user','item','rating', 'prediction'])\n",
    "\n",
    "toy_df.registerTempTable(\"toy_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+----------+-------------------+-------------------+------------+-------------+\n",
      "|user|item|rating|prediction|                dcg|               idcg|pred_row_num|ideal_row_num|\n",
      "+----+----+------+----------+-------------------+-------------------+------------+-------------+\n",
      "|   1|   5|     5|       3.8|                5.0|                5.0|           1|            1|\n",
      "|   1|   7|     5|       3.8|  3.154648767857287|  3.154648767857287|           2|            2|\n",
      "|   1|   8|     5|       3.8|                2.5|                2.5|           3|            3|\n",
      "|   1|   9|     5|       3.8| 2.1533827903669653| 2.1533827903669653|           4|            4|\n",
      "|   1|  10|     5|       3.8|  1.934264036172708|  1.934264036172708|           5|            5|\n",
      "|   1|   6|     4|       3.8| 1.4248287484320887| 1.4248287484320887|           6|            6|\n",
      "|   1|   2|     3|       3.8|                1.0|                1.0|           7|            7|\n",
      "|   1|   1|     1|       3.8| 0.3154648767857287| 0.3154648767857287|           8|            8|\n",
      "|   1|   3|     1|       3.8|0.30102999566398114|0.30102999566398114|           9|            9|\n",
      "|   1|   4|     1|       3.8| 0.2890648263178878| 0.2890648263178878|          10|           10|\n",
      "+----+----+------+----------+-------------------+-------------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.sql(\n",
    "'''\n",
    "select\n",
    "    user,\n",
    "    item,\n",
    "    rating,\n",
    "    prediction,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "            PARTITION BY user\n",
    "            ORDER BY prediction DESC\n",
    "        )\n",
    "    ) as dcg,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY rating DESC\n",
    "            )\n",
    "    ) as idcg,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY prediction DESC\n",
    "    ) as pred_row_num,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY rating DESC\n",
    "    ) as ideal_row_num\n",
    "from toy_df\n",
    "'''\n",
    ")\n",
    "df3.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+------------------+\n",
      "|user|item|rating|        prediction|\n",
      "+----+----+------+------------------+\n",
      "|   0|  18|     4| 4.205746043301845|\n",
      "|   0|  22|     4|2.7445256104127926|\n",
      "|   0|  32|     4| 4.983120720496773|\n",
      "|   0|  34|     3|1.9849535130973968|\n",
      "|   0|  35|     5|3.1966399651712267|\n",
      "|   0|  36|     3| 3.048048898588427|\n",
      "|   0|  50|     5|  3.90836757442086|\n",
      "|   0|  62|     4|3.8165881878911465|\n",
      "|   0|  70|     4| 4.047189576890129|\n",
      "|   0|  74|     5|2.6096747504398348|\n",
      "|   0|  78|     5|5.5969979073330896|\n",
      "|   0|  98|     5| 5.153708334731422|\n",
      "|   0| 116|     5| 3.998787456599543|\n",
      "|   0| 134|     3|3.4128474009978653|\n",
      "|   0| 136|     2|3.3225291797482783|\n",
      "|   0| 149|     5|3.0166765191445477|\n",
      "|   0| 161|     4|5.0159909166836005|\n",
      "|   0| 198|     5|2.5904302401800092|\n",
      "|   0| 217|     3|2.8331438417314114|\n",
      "|   0| 222|     5|3.2404804322849694|\n",
      "+----+----+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_rating_df = (\n",
    "    train_df\n",
    "    .agg(\n",
    "        F.avg('rating').alias('avg_rating')\n",
    "    )\n",
    ")\n",
    "\n",
    "train_predict_df = (\n",
    "    train_df\n",
    "    .crossJoin(avg_rating_df)\n",
    "    .withColumn(\n",
    "        'prediction',\n",
    "        F.col('avg_rating') + F.randn()\n",
    "    )\n",
    "    .select(\n",
    "        'user',\n",
    "        'item',\n",
    "        'rating',\n",
    "        'prediction'\n",
    "    )\n",
    ")\n",
    "\n",
    "train_predict_df.registerTempTable(\"train_predict_df\")\n",
    "\n",
    "train_predict_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df4 = spark.sql(\n",
    "'''\n",
    "select\n",
    "    user,\n",
    "    item,\n",
    "    rating,\n",
    "    prediction,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "            PARTITION BY user\n",
    "            ORDER BY prediction DESC\n",
    "        )\n",
    "    ) as dcg,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY rating DESC\n",
    "            )\n",
    "    ) as idcg,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY prediction DESC\n",
    "    ) as pred_row_num,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY rating DESC\n",
    "    ) as ideal_row_num\n",
    "from train_predict_df\n",
    "where user = 148\n",
    "order by pred_row_num\n",
    "'''\n",
    ")\n",
    "df4.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+------------------+\n",
      "|user|item|rating|        prediction|\n",
      "+----+----+------+------------------+\n",
      "|   0|  43|     5| 3.997778279805047|\n",
      "|   0|  77|     3| 2.749095691273272|\n",
      "|   0| 106|     4|  2.98862019165168|\n",
      "|   0| 146|     3|2.7637004759381076|\n",
      "|   0| 157|     4| 4.760402944730159|\n",
      "|   0| 188|     3| 3.750539876730257|\n",
      "|   0| 190|     4|3.9008672499591897|\n",
      "|   0| 236|     4|6.6272952593902765|\n",
      "|   0| 356|     5| 4.048894507629259|\n",
      "|   0| 366|     3|2.8464701861769406|\n",
      "|   0| 403|     2| 4.013454484871694|\n",
      "|   0| 408|     3|3.4838903594693447|\n",
      "|   0| 464|     4| 3.675176549501538|\n",
      "|   0| 533|     4| 5.499633001805129|\n",
      "|   0| 650|     3| 2.952754801739461|\n",
      "|   0| 713|     4| 3.829402855534937|\n",
      "|   0| 715|     4| 4.171312244671753|\n",
      "|   0| 785|     3| 5.251754628391863|\n",
      "|   0| 831|     4| 2.787791198773814|\n",
      "|   0| 883|     4|2.7472032621280515|\n",
      "+----+----+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict_df = (\n",
    "    test_df\n",
    "    .crossJoin(avg_rating_df)\n",
    "    .withColumn(\n",
    "        'prediction',\n",
    "        F.col('avg_rating') + F.randn()\n",
    "    )\n",
    "    .select(\n",
    "        'user',\n",
    "        'item',\n",
    "        'rating',\n",
    "        'prediction'\n",
    "    )\n",
    ")\n",
    "\n",
    "test_predict_df.registerTempTable(\"test_predict_df\")\n",
    "\n",
    "test_predict_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "|user|item|rating|        prediction|                dcg|               idcg|pred_row_num|ideal_row_num|\n",
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "| 148| 140|     5|  5.53996767641031|  3.154648767857287|                5.0|           2|            1|\n",
      "| 148|2422|     5| 5.140437539702793|  1.934264036172708|  3.154648767857287|           5|            2|\n",
      "| 148| 229|     5| 4.253518892461914|               1.25|                2.5|          15|            3|\n",
      "| 148|2226|     5| 4.128073243369231| 1.1568910657987959| 2.1533827903669653|          19|            4|\n",
      "| 148| 511|     5| 3.987186466592252|  1.138351243484765|  1.934264036172708|          20|            5|\n",
      "| 148| 488|     5| 3.843091267052496| 1.0637302677668157| 1.7810359355401109|          25|            6|\n",
      "| 148| 137|     5|3.6272064574936125|  1.018975235452531| 1.6666666666666667|          29|            7|\n",
      "| 148|  93|     5|3.4095335756383665| 1.0092454329104992| 1.5773243839286435|          30|            8|\n",
      "| 148|  43|     5|3.1505979947281926| 0.9911993158528026| 1.5051499783199058|          32|            9|\n",
      "| 148| 935|     5|  3.06625564598484| 0.9747951094689316| 1.4453241315894392|          34|           10|\n",
      "| 148| 325|     5|2.8843383020091524| 0.9597936000328007| 1.3947147282556491|          36|           11|\n",
      "| 148| 992|     5| 2.594645130562812|  0.952757062133867| 1.3511907721365988|          37|           12|\n",
      "| 148|2319|     4| 5.697729651007401|                4.0| 1.0505981401487743|           1|           13|\n",
      "| 148| 321|     4| 5.276649847014676| 1.7227062322935722|  1.023832099239262|           4|           14|\n",
      "| 148|3364|     4| 5.025171106408145| 1.4248287484320887|                1.0|           6|           15|\n",
      "| 148|3874|     4| 4.977447292249473| 1.2618595071429148| 0.9786021684729039|           8|           16|\n",
      "| 148|1928|     4| 4.700332881428415| 1.1157717826045193| 0.9592498662725258|          11|           17|\n",
      "| 148|1934|     4| 4.254169321351638|  1.023832099239262|  0.941635653466553|          14|           18|\n",
      "| 148| 848|     4| 4.221942673356503| 0.9786021684729039| 0.9255128526390366|          16|           19|\n",
      "| 148|1177|     4| 4.205054253595123| 0.9592498662725258|  0.910680994787812|          17|           20|\n",
      "| 148|2982|     4|3.8669587436928503| 0.8724171679421261| 0.8969752968703018|          23|           21|\n",
      "| 148|1360|     4| 3.636317539066696| 0.8320583907060379|  0.884258917830015|          27|           22|\n",
      "| 148|1412|     4|3.6304045827730786| 0.8233873298417377| 0.8724171679421261|          28|           23|\n",
      "| 148| 364|     4| 3.007254369813743| 0.7737056144690833| 0.8613531161467861|          35|           24|\n",
      "| 148| 897|     4| 1.419085507400185| 0.7516072988364303| 0.8509842142134525|          39|           25|\n",
      "| 148| 637|     3| 5.457976005843233|                1.5| 0.6309297535714573|           3|           26|\n",
      "| 148| 623|     3| 5.019457827448542|                1.0| 0.6240437930295284|           7|           27|\n",
      "| 148|1055|     3| 4.808655577625712| 0.9030899869919435| 0.6175404973813033|           9|           28|\n",
      "| 148|1073|     3| 4.765452227178382| 0.8671944789536634| 0.6113851412715186|          10|           29|\n",
      "| 148|1773|     3| 4.164229559360643| 0.7062267400999147| 0.6055472597462995|          18|           30|\n",
      "| 148| 223|     3| 3.944350311390328| 0.6727314726527263|                0.6|          21|           31|\n",
      "| 148|1945|     3| 3.857339079850364| 0.6460148371100897| 0.5947195895116816|          24|           32|\n",
      "| 148|1538|     3|3.7477284052106965| 0.6309297535714573| 0.5896848966984678|          26|           33|\n",
      "| 148|3002|     3| 3.230828912448846|                0.6| 0.5848770656813589|          31|           34|\n",
      "| 148| 135|     3|3.1259796025217836| 0.5896848966984678| 0.5802792108518124|          33|           35|\n",
      "| 148| 849|     2| 4.507528354735808| 0.5404763088546395| 0.3839174400131203|          12|           36|\n",
      "| 148| 442|     2| 4.309240607012506| 0.5252990700743871| 0.3811028248535468|          13|           37|\n",
      "| 148| 621|     2| 3.895914606024246| 0.4421294589150075|0.37840071903374006|          22|           38|\n",
      "| 148| 218|     2|2.3826034173175796|0.37840071903374006|0.37580364941821515|          38|           39|\n",
      "+----+----+------+------------------+-------------------+-------------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = spark.sql(\n",
    "'''\n",
    "select\n",
    "    user,\n",
    "    item,\n",
    "    rating,\n",
    "    prediction,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "            PARTITION BY user\n",
    "            ORDER BY prediction DESC\n",
    "        )\n",
    "    ) as dcg,\n",
    "    rating / log(2, 1 + \n",
    "        row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY rating DESC\n",
    "            )\n",
    "    ) as idcg,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY prediction DESC\n",
    "    ) as pred_row_num,\n",
    "    row_number() OVER (\n",
    "        PARTITION BY user\n",
    "        ORDER BY rating DESC\n",
    "    ) as ideal_row_num\n",
    "from test_predict_df\n",
    "where user = 148\n",
    "'''\n",
    ")\n",
    "df5.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043437563021476056"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = spark.sql(\n",
    "'''\n",
    "select 1 - avg(p.dcg / a.idcg) as ndcg\n",
    "from (\n",
    "    select\n",
    "        x.user,\n",
    "        sum(x.rating / log(2, 1 + x.pred_row_num)) as dcg\n",
    "    from (\n",
    "        select\n",
    "            user,\n",
    "            rating,\n",
    "            row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY prediction DESC\n",
    "            ) as pred_row_num\n",
    "        from predictions_df\n",
    "    ) x \n",
    "    where x.pred_row_num <= 10\n",
    "    group by x.user\n",
    ") p\n",
    "join (\n",
    "    select\n",
    "        x.user,\n",
    "        sum(x.rating / log(2, 1 + x.actual_row_num)) as idcg\n",
    "    from (\n",
    "        select\n",
    "            user,\n",
    "            rating,\n",
    "            row_number() OVER (\n",
    "                PARTITION BY user\n",
    "                ORDER BY rating DESC\n",
    "            ) as actual_row_num\n",
    "        from predictions_df\n",
    "    ) x \n",
    "    where x.actual_row_num <= 10\n",
    "    group by x.user\n",
    ") a on a.user = p.user\n",
    "''')\n",
    "\n",
    "df6.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test top N ndcg implementation\n",
    "def eval_ndcg(df):\n",
    "    df.registerTempTable(\"df\")\n",
    "    \n",
    "    score_df = spark.sql(\n",
    "    '''\n",
    "    select 1 - avg(p.dcg / a.idcg) as ndcg\n",
    "    from (\n",
    "        select\n",
    "            x.user,\n",
    "            sum(x.rating / log(2, 1 + x.pred_row_num)) as dcg\n",
    "        from (\n",
    "            select\n",
    "                user,\n",
    "                rating,\n",
    "                row_number() OVER (\n",
    "                    PARTITION BY user\n",
    "                    ORDER BY prediction DESC\n",
    "                ) as pred_row_num\n",
    "            from df\n",
    "        ) x \n",
    "        where x.pred_row_num <= 10\n",
    "        group by x.user\n",
    "    ) p\n",
    "    join (\n",
    "        select\n",
    "            x.user,\n",
    "            sum(x.rating / log(2, 1 + x.actual_row_num)) as idcg\n",
    "        from (\n",
    "            select\n",
    "                user,\n",
    "                rating,\n",
    "                row_number() OVER (\n",
    "                    PARTITION BY user\n",
    "                    ORDER BY rating DESC\n",
    "                ) as actual_row_num\n",
    "            from df\n",
    "        ) x \n",
    "        where x.actual_row_num <= 10\n",
    "        group by x.user\n",
    "    ) a on a.user = p.user\n",
    "    '''\n",
    "    )\n",
    "    \n",
    "    return score_df.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ndcg:  0.04283937609480404\n",
      "test ndcg:  0.0357604036771193\n",
      "train ndcg_10:  0.08370289899941341\n",
      "test ndcg_10:  0.043437563021476056\n"
     ]
    }
   ],
   "source": [
    "print('train ndcg: ', ndcg_evaluator.evaluate(train_predictions_df))\n",
    "print('test ndcg: ', ndcg_evaluator.evaluate(predictions_df))\n",
    "print('train ndcg_10: ', eval_ndcg(train_predictions_df))\n",
    "print('test ndcg_10: ', eval_ndcg(predictions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_predict_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fbaffcd83c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random train ndcg: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predict_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random test ndcg: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random train ndcg_10: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ndcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predict_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random test ndcg_10: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ndcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_predict_df' is not defined"
     ]
    }
   ],
   "source": [
    "print('random train ndcg: ', ndcg_evaluator.evaluate(train_predict_df))\n",
    "print('random test ndcg: ', ndcg_evaluator.evaluate(test_predict_df))\n",
    "print('random train ndcg_10: ', eval_ndcg(train_predict_df))\n",
    "print('random test ndcg_10: ', eval_ndcg(test_predict_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
